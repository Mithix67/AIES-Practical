{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mithix67/AIES-Practical/blob/main/Exp-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:-Mithul CE\n",
        "Class:- B.Tech A DIV\n",
        "PRN NO. 22SC114501026\n",
        "Title:- Impact of Data Quality on AI Fairness.\n",
        "     "
      ],
      "metadata": {
        "id": "3XMaZlg6duoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj85ecJUe4jz",
        "outputId": "5eb70e06-0134-46fd-dd14-5ee51e17ec42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n",
            "🎯 Fairness Metrics by Category:\n",
            "\n",
            "               TPR       FPR       FNR  Selection Rate\n",
            "category                                              \n",
            "GEN       0.200000  0.166667  0.800000        0.178571\n",
            "OBC-NCL   0.000000  0.222222  1.000000        0.130435\n",
            "SC        0.000000  0.157895  1.000000        0.088235\n",
            "ST        0.166667  0.125000  0.833333        0.142857\n",
            "\n",
            "🔍 Categories with significantly lower TPR than GEN:\n",
            " - OBC-NCL: TPR = 0.000 (↓0.200)\n",
            " - SC: TPR = 0.000 (↓0.200)\n"
          ]
        }
      ],
      "source": [
        "!pip install fairlearn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from fairlearn.metrics import MetricFrame, true_positive_rate, false_positive_rate, false_negative_rate, selection_rate\n",
        "\n",
        "# === Step 1: Create synthetic dataset ===\n",
        "np.random.seed(42)\n",
        "n = 500\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'closing_rank': np.random.randint(1, 5000, size=n),\n",
        "    'category': np.random.choice(['GEN', 'OBC-NCL', 'SC', 'ST'], size=n, p=[0.4, 0.3, 0.2, 0.1]),\n",
        "    'program_duration': np.random.choice(['3 Years', '4 Years'], size=n),\n",
        "    'degree_short': np.random.choice(['BTech', 'BSc', 'BA'], size=n),\n",
        "    'institute_short': np.random.choice(['IIT', 'NIT', 'IIIT'], size=n),\n",
        "    'round_no': np.random.randint(1, 7, size=n),\n",
        "    'opening_rank': np.random.randint(1, 5000, size=n)\n",
        "})\n",
        "\n",
        "# Target: Good Rank\n",
        "df['GoodRank'] = (df['closing_rank'] < 2000).astype(int)\n",
        "\n",
        "# Sensitive attribute\n",
        "sensitive_feature = df['category']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df_encoded = pd.get_dummies(\n",
        "    df[['program_duration', 'degree_short', 'institute_short']],\n",
        "    drop_first=True\n",
        ")\n",
        "df_numeric = df[['round_no', 'opening_rank']].copy()\n",
        "X = pd.concat([df_numeric, df_encoded], axis=1)\n",
        "y = df['GoodRank']\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test, s_train, s_test = train_test_split(\n",
        "    X, y, sensitive_feature, test_size=0.3, random_state=42, stratify=sensitive_feature\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Fairness Metrics\n",
        "metric_frame = MetricFrame(\n",
        "    metrics={\n",
        "        'TPR': true_positive_rate,\n",
        "        'FPR': false_positive_rate,\n",
        "        'FNR': false_negative_rate,\n",
        "        'Selection Rate': selection_rate\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    sensitive_features=s_test\n",
        ")\n",
        "\n",
        "print(\"🎯 Fairness Metrics by Category:\\n\")\n",
        "print(metric_frame.by_group)\n",
        "\n",
        "# Highlight lower TPR groups\n",
        "if 'GEN' in metric_frame.by_group.index:\n",
        "    gen_tpr = metric_frame.by_group.loc['GEN', 'TPR']\n",
        "    print(\"\\n🔍 Categories with significantly lower TPR than GEN:\")\n",
        "    for cat in metric_frame.by_group.index:\n",
        "        if cat != 'GEN':\n",
        "            cat_tpr = metric_frame.by_group.loc[cat, 'TPR']\n",
        "            gap = gen_tpr - cat_tpr\n",
        "            if gap > 0.05:\n",
        "                print(f\" - {cat}: TPR = {cat_tpr:.3f} (↓{gap:.3f})\")\n",
        "else:\n",
        "    print(\"\\n⚠ No 'GEN' category found.\")\n"
      ]
    }
  ]
}